{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from typing import Tuple, Any\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absolute_path</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D:\\python\\dataset\\leopard\\0000.jpg</td>\n",
       "      <td>leopard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D:\\python\\dataset\\leopard\\0001.jpg</td>\n",
       "      <td>leopard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D:\\python\\dataset\\leopard\\0002.jpg</td>\n",
       "      <td>leopard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D:\\python\\dataset\\leopard\\0003.jpg</td>\n",
       "      <td>leopard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D:\\python\\dataset\\leopard\\0004.jpg</td>\n",
       "      <td>leopard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2035</th>\n",
       "      <td>D:\\python\\dataset\\tiger\\1015.jpg</td>\n",
       "      <td>tiger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036</th>\n",
       "      <td>D:\\python\\dataset\\tiger\\1016.jpg</td>\n",
       "      <td>tiger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>D:\\python\\dataset\\tiger\\1017.jpg</td>\n",
       "      <td>tiger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2038</th>\n",
       "      <td>D:\\python\\dataset\\tiger\\1018.jpg</td>\n",
       "      <td>tiger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2039</th>\n",
       "      <td>D:\\python\\dataset\\tiger\\1019.jpg</td>\n",
       "      <td>tiger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2040 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           absolute_path    class\n",
       "0     D:\\python\\dataset\\leopard\\0000.jpg  leopard\n",
       "1     D:\\python\\dataset\\leopard\\0001.jpg  leopard\n",
       "2     D:\\python\\dataset\\leopard\\0002.jpg  leopard\n",
       "3     D:\\python\\dataset\\leopard\\0003.jpg  leopard\n",
       "4     D:\\python\\dataset\\leopard\\0004.jpg  leopard\n",
       "...                                  ...      ...\n",
       "2035    D:\\python\\dataset\\tiger\\1015.jpg    tiger\n",
       "2036    D:\\python\\dataset\\tiger\\1016.jpg    tiger\n",
       "2037    D:\\python\\dataset\\tiger\\1017.jpg    tiger\n",
       "2038    D:\\python\\dataset\\tiger\\1018.jpg    tiger\n",
       "2039    D:\\python\\dataset\\tiger\\1019.jpg    tiger\n",
       "\n",
       "[2040 rows x 2 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv = \"D:/python/annotation_dataset.csv\"\n",
    "data = pd.read_csv(csv,  usecols=[0, 2])\n",
    "(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = set(data[\"class\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "splited_by_class, train_list, test_list, val_list = pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "i = 0\n",
    "for name in names:\n",
    "    splited_by_class = data.loc[data['class'] == name]\n",
    "    train_list = pd.concat([train_list, splited_by_class[0 : int(len(splited_by_class) * 0.8)]], )\n",
    "    test_list = pd.concat([test_list, splited_by_class[int(len(splited_by_class) * 0.8) : int(len(splited_by_class) * 0.9)]], ignore_index = True)\n",
    "    val_list = pd.concat([val_list, splited_by_class[int(len(splited_by_class) * 0.9) : int(len(splited_by_class))]], ignore_index = True)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка на сбалансированность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "train_stats = train_list['class'].value_counts()\n",
    "test_stats = train_list['class'].value_counts()\n",
    "val_stats = train_list['class'].value_counts()\n",
    "if not train_stats.min() / train_stats.max() >= 0.98:\n",
    "    print(\"not ok\")\n",
    "elif not test_stats.min() / test_stats.max() >= 0.98:\n",
    "    print(\"not ok\")\n",
    "elif not val_stats.min() / val_stats.max() >= 0.98:\n",
    "    print(\"not ok\")\n",
    "else:\n",
    "    print(\"ok\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Класс для хранения картинок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "  \"\"\"Class to store images\"\"\"\n",
    "  def __init__(self, images, transform:Any=None) -> None:\n",
    "        self.dataset = images\n",
    "        self.transform = transform\n",
    "\n",
    "  def __len__(self) -> int:\n",
    "    return len(self.dataset_info)\n",
    "\n",
    "  def __getitem__(self, index: int) -> Tuple[torch.tensor, int]:\n",
    "    path_to_image = self.dataset.iloc[index, 0]\n",
    "    image = cv2.cvtColor(cv2.imread(path_to_image), cv2.COLOR_BGR2RGB)\n",
    "    image = self.transform(image)\n",
    "    label = self.dataset.iloc[index, 1]\n",
    "\n",
    "    if label == \"tiger\":\n",
    "       label = 0\n",
    "    elif label == \"leopard\":\n",
    "       label = 1\n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "absolute_path    D:\\python\\dataset\\tiger\\0000.jpg\n",
       "class                                       tiger\n",
       "Name: 1020, dtype: object"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_list.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zabir\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.7607, 0.7455, 0.7292,  ..., 0.9474, 0.9613, 0.9772],\n",
       "          [0.9291, 0.9291, 0.9272,  ..., 0.9474, 0.9613, 0.9646],\n",
       "          [0.8630, 0.8630, 0.8680,  ..., 0.9421, 0.9474, 0.9635],\n",
       "          ...,\n",
       "          [2.0020, 1.9795, 1.9406,  ..., 2.0764, 2.0764, 2.0764],\n",
       "          [2.0443, 2.0353, 2.0180,  ..., 2.0838, 2.0838, 2.0838],\n",
       "          [2.1161, 2.0817, 2.0569,  ..., 2.0813, 2.0813, 2.0813]],\n",
       " \n",
       "         [[0.9946, 0.9792, 0.9625,  ..., 1.1856, 1.1998, 1.2160],\n",
       "          [1.1668, 1.1668, 1.1649,  ..., 1.1856, 1.1998, 1.2031],\n",
       "          [1.0993, 1.0993, 1.1044,  ..., 1.1801, 1.1856, 1.2020],\n",
       "          ...,\n",
       "          [2.3337, 2.3107, 2.2709,  ..., 2.2698, 2.2698, 2.2698],\n",
       "          [2.3769, 2.3678, 2.3500,  ..., 2.2648, 2.2648, 2.2648],\n",
       "          [2.4246, 2.4152, 2.3898,  ..., 2.2397, 2.2397, 2.2397]],\n",
       " \n",
       "         [[1.5436, 1.5282, 1.5116,  ..., 1.7511, 1.7653, 1.7814],\n",
       "          [1.7150, 1.7150, 1.7131,  ..., 1.7511, 1.7653, 1.7685],\n",
       "          [1.6478, 1.6478, 1.6528,  ..., 1.7444, 1.7499, 1.7662],\n",
       "          ...,\n",
       "          [2.4957, 2.4789, 2.4656,  ..., 2.5516, 2.5516, 2.5516],\n",
       "          [2.5363, 2.5314, 2.5319,  ..., 2.5529, 2.5529, 2.5529],\n",
       "          [2.6094, 2.5744, 2.5491,  ..., 2.5392, 2.5392, 2.5392]]]),\n",
       " 0)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_transforms = transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        torchvision.transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "        ]\n",
    ")\n",
    "train_data = CustomDataset(train_list, transform=custom_transforms)\n",
    "test_data = CustomDataset(test_list, transform=custom_transforms)\n",
    "val_data = CustomDataset(val_list, transform=custom_transforms)\n",
    "val_data.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель свёрточной нейросети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=0, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=0, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "            )\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=0, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(576, 10)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc2 = nn.Linear(10, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x: torch.tensor) -> torch.tensor:\n",
    "        output = self.layer1(x)\n",
    "        output = self.layer2(output)\n",
    "        output = self.layer3(output)\n",
    "        output = torch.nn.Flatten()(output)\n",
    "        output = self.relu(self.fc1(output))\n",
    "        output = self.fc2(output)\n",
    "        return torch.nn.Sigmoid()(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc1): Linear(in_features=576, out_features=10, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (fc2): Linear(in_features=10, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "if device =='cuda':\n",
    "    torch.cuda.manual_seed_all(1234)\n",
    "    \n",
    "model = CNN()\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Графики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chart(epochs, train_acc, train_loss, valid_acc, valid_loss) -> None:\n",
    "    \"\"\"Creates graphs based on the learning results\"\"\"\n",
    "    fig=plt.figure(figsize=(20, 10))\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.title('Neural network training results')\n",
    "    plt.plot(range(epochs), train_acc, color='green', linestyle='-', linewidth=1, label='Train accuracy') \n",
    "    plt.plot(range(epochs) ,train_loss, color='red', linestyle='--', linewidth=1, label='Train loss')\n",
    "    plt.legend() \n",
    "    plt.show()\n",
    "\n",
    "    fig=plt.figure(figsize=(20, 10))\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.title('Neural network training results')\n",
    "    plt.plot(range(epochs), valid_acc, color='green', linestyle='-', linewidth=1, label='Validation accuracy') \n",
    "    plt.plot(range(epochs) ,valid_loss, color='red', linestyle='--', linewidth=1, label='Validation loss')\n",
    "    plt.legend() \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(epochs, batch_size, lear) -> Tuple[list, CNN]:\n",
    "    optimizer = optim.Adam(params=model.parameters(), lr=lear)\n",
    "    criterion = nn.BCELoss(reduction='sum')\n",
    "    train_accuracy_values = []\n",
    "    train_loss_values = []\n",
    "\n",
    "    val_accuracy_values = []\n",
    "    val_loss_values = []\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_data, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        dataset=val_data, batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        epoch_accuracy = 0\n",
    "        model.train()\n",
    "        for data, label in train_loader: # 400\n",
    "            data = data.to(cuda)\n",
    "            label = label.to(cuda)\n",
    "\n",
    "            output = model(data)\n",
    "            loss = criterion(output, label.unsqueeze(dim=1).to(torch.float))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            acc = np.array(([1 if (1 if output[j][0].detach() >= 0.5 else 0) == int(label[j]) else 0 for j in range(batch_size)])).sum()\n",
    "\n",
    "            epoch_accuracy += acc / len(train_loader)\n",
    "            epoch_loss += loss / len(train_loader)\n",
    "\n",
    "        train_accuracy_values.append(epoch_accuracy)\n",
    "        train_loss_values.append(epoch_loss)\n",
    "    print(f'Epoch : {epoch + 1}, train accuracy : {epoch_accuracy}, train loss : {epoch_loss}')\n",
    "\n",
    "    model.eval()\n",
    "    epoch_val_accuracy = 0\n",
    "    epoch_val_loss = 0\n",
    "    for data, label in valid_loader:\n",
    "        data = data.to(cuda)\n",
    "        label = label.to(cuda)\n",
    "        output = model(data)\n",
    "        loss = criterion(output, label.unsqueeze(dim=1).to(torch.float))\n",
    "        acc = np.array(([1 if (1 if output[j][0].detach() >= 0.5 else 0) == int(label[j]) else 0 for j in range(4)])).sum()\n",
    "        epoch_val_accuracy += acc / len(valid_loader)\n",
    "        epoch_val_loss += loss / len(valid_loader)\n",
    "\n",
    "    val_accuracy_values.append(epoch_val_accuracy)\n",
    "    val_loss_values.append(epoch_val_loss)\n",
    "\n",
    "    print(f\"Epoch : {epoch + 1}, val_accuracy : {epoch_val_accuracy}, val_loss : {epoch_val_loss}\")\n",
    "    chart(epochs, train_accuracy_values, train_loss_values, val_accuracy_values, val_loss_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CustomDataset' object has no attribute 'dataset_info'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\python\\Lab5\\tests.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/python/Lab5/tests.ipynb#X40sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_loop(\u001b[39m10\u001b[39;49m, \u001b[39m100\u001b[39;49m, \u001b[39m0.001\u001b[39;49m)\n",
      "\u001b[1;32md:\\python\\Lab5\\tests.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/python/Lab5/tests.ipynb#X40sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m valid_loss_values \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/python/Lab5/tests.ipynb#X40sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m valid_loader \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/python/Lab5/tests.ipynb#X40sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     dataset\u001b[39m=\u001b[39mval_data, batch_size\u001b[39m=\u001b[39mbatch_size, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/python/Lab5/tests.ipynb#X40sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/python/Lab5/tests.ipynb#X40sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m train_loader \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mutils\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mDataLoader(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/python/Lab5/tests.ipynb#X40sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     dataset\u001b[39m=\u001b[39;49mtrain_data, batch_size\u001b[39m=\u001b[39;49mbatch_size, shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/python/Lab5/tests.ipynb#X40sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/python/Lab5/tests.ipynb#X40sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/python/Lab5/tests.ipynb#X40sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     epoch_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:349\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[1;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# map-style\u001b[39;00m\n\u001b[0;32m    348\u001b[0m     \u001b[39mif\u001b[39;00m shuffle:\n\u001b[1;32m--> 349\u001b[0m         sampler \u001b[39m=\u001b[39m RandomSampler(dataset, generator\u001b[39m=\u001b[39;49mgenerator)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    350\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    351\u001b[0m         sampler \u001b[39m=\u001b[39m SequentialSampler(dataset)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\sampler.py:139\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[1;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplacement, \u001b[39mbool\u001b[39m):\n\u001b[0;32m    137\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplacement\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 139\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_samples, \u001b[39mint\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    140\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\sampler.py:146\u001b[0m, in \u001b[0;36mRandomSampler.num_samples\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m    143\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnum_samples\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mint\u001b[39m:\n\u001b[0;32m    144\u001b[0m     \u001b[39m# dataset size might change at runtime\u001b[39;00m\n\u001b[0;32m    145\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_samples \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_source)\n\u001b[0;32m    147\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_samples\n",
      "\u001b[1;32md:\\python\\Lab5\\tests.ipynb Cell 21\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/python/Lab5/tests.ipynb#X40sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__len__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mint\u001b[39m:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/python/Lab5/tests.ipynb#X40sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset_info)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'CustomDataset' object has no attribute 'dataset_info'"
     ]
    }
   ],
   "source": [
    "train_loop(10, 100, 0.001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
